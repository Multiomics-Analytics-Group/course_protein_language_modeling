{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06460c02-2004-436b-aa38-1ae0a7587052",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/Multiomics-Analytics-Group/course_protein_language_modeling/blob/main/img/nb_logo.png?raw=1\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf874eb-8949-41dd-a33b-0e55ba2954c6",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Multiomics-Analytics-Group/course_protein_language_modeling/blob/main/notebooks/embeddings.ipynb)\n",
    "\n",
    "\n",
    "This is a version of the notebook from [SETH](https://github.com/DagmarIlz/SETH) --- [here](https://colab.research.google.com/drive/1vDWh5YI_BPxQg0ku6CxKtSXEJ25u2wSq?usp=sharing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6f0c8f-d9db-4623-a2ee-483008dc9d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"transformers[torch]\" sentencepiece h5py biopython > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efcc6ce-9843-4541-a6de-6b3a6ba14c45",
   "metadata": {},
   "source": [
    "<h3><span style=\"color:red\">Important</span></h3> \n",
    "If you are running in Google Colab, change the Notebook settings to use `GPU`.\n",
    "\n",
    "Just follow **Edit** > **Notebook settings** or **Runtime** > **Change runtime type** and select **GPU** as Hardware accelerator.\n",
    "\n",
    "![gpu.png](../img/gpu.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75061fa6-eea7-42dc-b057-5da1c56094c0",
   "metadata": {
    "id": "5c0749e1"
   },
   "source": [
    "# Embedding Protein Sequences\n",
    "\n",
    "In this notebook, we will use a pre-trained language model, [ProtT5-XL-UniRef50](https://huggingface.co/Rostlab/prot_t5_xl_uniref50), to encode the protein sequences of 5000+ $\\beta$-$lactamase$ TEM-type varients from FASTA file [P62593.fasta](https://github.com/facebookresearch/esm/blob/2b369911bb5b4b0dda914521b9475cad1656b2ac/examples/data/P62593.fasta). This data was subsetted from a deep mutational scan released by [Gray et al. (2018)](https://www.cell.com/cell-systems/pdfExtended/S2405-4712(17)30492-1). \n",
    "\n",
    "The goal of this notebook is to obtain an embedding (fixed-dimensional vector representation) for each mutated sequence.\n",
    "\n",
    "Although the embedding won't capture all the information from the original data, good embedding representations allow us to analyze, cluster, or use them as features to train machine learning models. \n",
    "\n",
    "The embeddings generated in this notebook will then be used in the next exercise (prediction.ipynb) to train a simple varient predictor (i.e., predict the activity of the protein mutation)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b6f6b9-0778-4435-a515-e9616522c4b3",
   "metadata": {},
   "source": [
    "<div class=\"warning\" style='background-color:#E9D8FD; color: #69337A; border-left: solid #805AD5 4px; border-radius: 4px; padding:0.7em;'>\n",
    "<span>\n",
    "<p style='margin-top:1em; text-align:center'><b>NOTE</b></p>\n",
    "<p style='margin-left:1em;'>\n",
    "    Even when using GPU, embedding the protein sequences takes some time (~25mins) so to begin go ahead and run all cells of this notebook so that the process is started in the background as we review the notebook.\n",
    "</p>\n",
    "<p style='margin-top:1em; text-align:center'>\n",
    "    A shortcut to running all cells is going to the \"Runtime\" menu and selecting \"Run all\".\n",
    "\n",
    "</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5c4fc2-00ea-4e24-90fa-d96bf3751810",
   "metadata": {
    "id": "5c0749e1"
   },
   "source": [
    "----\n",
    "\n",
    "## The Data: P62593 Sequences\n",
    "\n",
    "To start we will import and explore the dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e520014b-391d-41b0-ad62-7d51f56511b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up working directories and download files/checkpoints \n",
    "!mkdir protT5 # directory for storing checkpoints, results etc\n",
    "!mkdir protT5/output # directory for storing your embeddings\n",
    "!curl -o P62593.fasta https://dl.fbaipublicfiles.com/fair-esm/examples/P62593.fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfc1b48-24d6-4d6f-86aa-9d3048a6d1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "from transformers import T5EncoderModel, T5Tokenizer\n",
    "import torch\n",
    "import h5py\n",
    "import time\n",
    "from Bio import SeqIO\n",
    "\n",
    "# Path variables\n",
    "per_protein_path = \"./protT5/output/per_protein_embeddings.h5\" # where to store the embeddings\n",
    "seq_path = 'P62593.fasta' # where the fasta file is saved\n",
    "\n",
    "# check whether GPU is available\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009ac9f9-b169-4696-abf6-a1c0a3ef8edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_fasta(fasta_path:str) -> dict:\n",
    "    '''\n",
    "    reads in fasta file and returns a dictionary with primary id/sequence key/value pairs \n",
    "    '''\n",
    "    \n",
    "    # dictionary to append to\n",
    "    seqs = {}\n",
    "    \n",
    "    # read in and parse fasta file\n",
    "    with open(fasta_path) as handle:\n",
    "        for record in SeqIO.parse(handle, \"fasta\"):\n",
    "            # append each varient to the dict\n",
    "            seqs[record.id] = record.seq\n",
    "\n",
    "    # verbose\n",
    "    example_id=next(iter(seqs))\n",
    "    print(f\"Read {len(seqs)} sequences.\")\n",
    "    print(f\"Example:\\nKey: {example_id}\\nValue: {seqs[example_id]}\")\n",
    "\n",
    "    return seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa98336-a298-4f5f-87b6-98718ec5e22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in file\n",
    "fasta_output = read_fasta(seq_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717503ab-a593-4af2-8128-4e64491c3ebc",
   "metadata": {},
   "source": [
    "In the FASTA file there are 5,397 sequences. As we can see in the example above from our fasta dictionary, each entry contains:\n",
    "\n",
    "- key: `{index}|beta-lactamase_{mutation}|{scaled_varient_effect}`\n",
    "    > in prediction.ipynb we will be predicting the `scaled_varient_effect` value, which describes the scaled effect of the mutation. \n",
    "- value: the mutated $\\beta$-lactamase sequence, where a single residue is mutated (swapped with another amino acid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef06a40d-a52f-46bf-bfe7-3b2374eea224",
   "metadata": {},
   "source": [
    "## The Model: ProtT5-XL-UniRef50\n",
    "\n",
    "ProtT5-XL-UniRef50 is based on the t5-3b model and was pretrained on a large corpus of protein sequences in a self-supervised fashion. This means it was pretrained on the raw protein sequences only, with **no humans-in-the-loop labelling** them in any way (which is why it can use lots of publicly available data) with an automatic process to generate inputs and labels from those protein sequences.\n",
    "\n",
    "This model only contains the encoder portion of the original ProtT5-XL-UniRef50 model using half precision (float16). As such, this model can efficiently be used to create protein/ amino acid representations. When used for training downstream networks/ feature extraction, these embeddings produced the same performance (established empirically by comparing on several downstream tasks). \n",
    "\n",
    "In the following cells we will prepare functions that will later assist us when generating the embeddings. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d072fe5a-3d34-475b-b025-abb7f3eef1f8",
   "metadata": {},
   "source": [
    "### `get_T5_model()` Load encoder-part of ProtT5 in half-precision\n",
    "\n",
    "To start we create a function that will load the model and associated tokenizer. Recall from the previous notebook (model_training.ipynb) where every model on `transformers` comes with an associated `tokenizer` that handles tokenization for it, where tokenization for protein language models involve coverting each amino acid to a single token.\n",
    "\n",
    "**Recall: Fine-tuning flow chart from the previous notebook**\n",
    "![Chart of the pretrained model fine-tuning process](../img/fine-tuning.png)\n",
    "\n",
    "\n",
    "This function accomplishes the \"Model Checkpoint Loading\" step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1c2e47-9131-41f6-b39b-2da11b4afe2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ProtT5 in half-precision (more specifically: the encoder-part of ProtT5-XL-U50) \n",
    "def get_T5_model():\n",
    "    '''\n",
    "    retrieves the model and tokenizer\n",
    "    '''\n",
    "    # specify the encorder-part of the model \n",
    "    model_checkpoint = 'Rostlab/prot_t5_xl_half_uniref50-enc'\n",
    "    \n",
    "    # import the model \n",
    "    model = T5EncoderModel.from_pretrained(model_checkpoint)\n",
    "    \n",
    "    model = model.to(device) # move model to GPU\n",
    "    model = model.eval() # set model to evaluation model\n",
    "    \n",
    "    # import tokenizer\n",
    "    tokenizer = T5Tokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4404313f-0c46-4cae-acea-5bfdbe86bd99",
   "metadata": {},
   "source": [
    "Let's use the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5282b4cc-36f4-4c70-93f2-5fb32a67f6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading model\n",
    "model, tokenizer = get_T5_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef88997-d8c8-4c62-b394-1d2c3b005a4f",
   "metadata": {},
   "source": [
    "### `get_embeddings()` Using the model to generate the embeddings\n",
    "\n",
    "From the flow chart above, the function `get_embeddings()` includes the 'Tokenization' and 'Dataset Creation' steps. Additionally, the model will encode the sequences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261698df-2497-4f6d-89ef-1df09736110a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(model, tokenizer, seqs, max_seq_len=1000, max_batch=100):\n",
    "    '''\n",
    "    use the encoder to embbed the sequences via batch-processing\n",
    "    -----\n",
    "    \n",
    "    parameters:\n",
    "        model: from get_T5_model()\n",
    "        tokenizer: from get_T5_model()\n",
    "        seqs: the dictionary of sequences generated by read_fasta() \n",
    "        max_seq_length: the upper sequences length for applying batch-processing\n",
    "        max_batch: the upper number of sequences per batch\n",
    "        \n",
    "    returns:\n",
    "        results: a dictionary containing the embedding representations of the sequences\n",
    "    '''\n",
    "\n",
    "    # initialize a dictionary, the embeddings will be accessible from results['protein_embs'] \n",
    "    results = {\"protein_embs\" : dict()}\n",
    "\n",
    "    # sort sequences according to length (reduces unnecessary padding --> speeds up embedding)\n",
    "    seq_dict = sorted(seqs.items(), \n",
    "                      # 'key' option is a function that serves as a basis of sort comparison.\n",
    "                      key=lambda kv: len(seqs[kv[0]]), \n",
    "                      # sort by descending order\n",
    "                      reverse=True\n",
    "                     )\n",
    "    \n",
    "    # for time tracking\n",
    "    start = time.time()\n",
    "    \n",
    "    # initialize empty list\n",
    "    batch = list()\n",
    "    \n",
    "    # for each item in the dictionary\n",
    "    for seq_idx, (pdb_id, seq) in enumerate(seq_dict, 1):\n",
    "        \n",
    "        # add space between residues\n",
    "        seq = ' '.join(list(seq))\n",
    "        \n",
    "        # length of sequence with spaces\n",
    "        seq_len = len(seq)\n",
    "        \n",
    "        # append to batch list as tuple\n",
    "        batch.append((pdb_id, seq, seq_len))\n",
    "\n",
    "        # creates n-tuple pairs from each element in batch\n",
    "        pdb_ids, seqs, seq_lens = zip(*batch)\n",
    "        \n",
    "        # empty list\n",
    "        batch = list()\n",
    "        \n",
    "        # Data Preparation and Tokenization:\n",
    "\n",
    "        # add_special_tokens adds extra token at the end of each sequence\n",
    "        token_encoding = tokenizer.batch_encode_plus(seqs, add_special_tokens=True, padding=\"longest\")\n",
    "        \n",
    "        # making the tokenized sequence into a tensor\n",
    "        input_ids = torch.tensor(token_encoding['input_ids']).to(device)\n",
    "        \n",
    "        # now making the mask into a tensor\n",
    "        attention_mask = torch.tensor(token_encoding['attention_mask']).to(device)\n",
    "        \n",
    "        # Generate Embedding:\n",
    "        \n",
    "        # using the model to encode the sequence, generating an embedding representation\n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                embedding_repr = model(input_ids, attention_mask=attention_mask)\n",
    "                # verbosity for progress tracking\n",
    "                print(f'Currently, embedding {pdb_id}')\n",
    "        except RuntimeError:\n",
    "            print(\"RuntimeError during embedding for {} (L={})\".format(pdb_id, seq_len))\n",
    "            continue\n",
    "            \n",
    "        # Putting together the dataset:\n",
    "        \n",
    "        # slice off padding if any \n",
    "        emb = embedding_repr.last_hidden_state[0,:seq_len]\n",
    "\n",
    "        # average along column\n",
    "        protein_emb = emb.mean(dim=0)\n",
    "\n",
    "        # save the embedding into results dictionary where the key = the fasta file entry header\n",
    "        results[\"protein_embs\"][pdb_id] = protein_emb.detach().cpu().numpy().squeeze()\n",
    "\n",
    "    # get time elapsed\n",
    "    passed_time=time.time()-start\n",
    "    avg_time = passed_time/len(results[\"protein_embs\"])\n",
    "    \n",
    "    # final verbose\n",
    "    print('\\n############# EMBEDDING STATS #############')\n",
    "    print('Total number of per-protein embeddings: {}'.format(len(results[\"protein_embs\"])))\n",
    "    print(\"Time for generating embeddings: {:.1f}[m] ({:.3f}[s/protein])\".format(\n",
    "        passed_time/60, avg_time ))\n",
    "    print('\\n############# END #############')\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ccafd2-6032-4e50-be6a-53e98897f922",
   "metadata": {},
   "source": [
    "**NOTE: What are special tokens?** \n",
    "\n",
    "Special tokens aren't present in the input text, but carry important meaning that we want the model to act on. For exmaple (not spevific to our model): \n",
    "- [PAD] Padding token — Added to the end of shorter inputs so that all inputs have the same length. This is because inputs to a neural network model are typically batched and the model operates on entire batches. \n",
    "- [UNK] Unknown token — Used to limit the number of distinct tokens. For example, if we want a vocabulary of at most 1000 tokens but the input text has 1200, then the remaining 200 will be converted to [UNK].\n",
    "    \n",
    "You can read more [here](https://medium.com/@alexkubiesa/special-tokens-in-tensorflow-3c7718dcb0ef).\n",
    "\n",
    "We will move on and use the function to get the embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4097b1-8da4-4cd7-9be1-4caf817294ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute embeddings\n",
    "results = get_embeddings(model, tokenizer, fasta_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2e3350-2791-4773-99f2-e55113f288ea",
   "metadata": {},
   "source": [
    "### `save_embeddings()` Writing the embeddings to a file\n",
    "\n",
    "For our final function, we will write the embeddings to a file. We will load this file into prediction.ipynb to train machine learning models. This is also a copy of the embedding file in the reposition in _data/_. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6986186f-93f3-4efe-9597-3c60ce5059a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_embeddings(emb_dict:dict , out_path:str):\n",
    "    '''\n",
    "    takes the resulting embeddings from get_embeddings() and saves to a compressed h5 file\n",
    "    -----\n",
    "    \n",
    "    parameters:\n",
    "        emb_dict (dict): dictionary that is in results['protein_embs'] \n",
    "        out_path (str): path and filename where the embeddings will be saved\n",
    "    '''\n",
    "    \n",
    "    with h5py.File(str(out_path), \"w\") as hf:\n",
    "        for sequence_id, embedding in emb_dict.items():\n",
    "            hf.create_dataset(sequence_id, data=embedding)\n",
    "            \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea3a1d4-0091-4134-9773-0a901f644a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write embeddings to file\n",
    "save_embeddings(results[\"protein_embs\"], per_protein_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
