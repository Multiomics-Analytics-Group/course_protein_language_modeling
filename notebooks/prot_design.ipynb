{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "256c6689-b8e5-4896-a5f5-bf599d10d235",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/Multiomics-Analytics-Group/course_protein_language_modeling/blob/main/img/nb_logo.png?raw=1\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02621233-5717-4541-b523-58ab391e3d5b",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Multiomics-Analytics-Group/course_protein_language_modeling/blob/main/notebooks/prot_design.ipynb)\n",
    "\n",
    "\n",
    "This is a version of the notebook from [Martin Pacesa](https://people.epfl.ch/martin.pacesa) --- [here](https://colab.research.google.com/drive/15ucZMtrAeFE_YOBQ9FdrWlAngvljJ4ss?usp=sharing) and [ESMFold](https://github.com/facebookresearch/esm/tree/main/esm/esmfold/v1) -- [here](https://colab.research.google.com/github/sokrypton/ColabFold/blob/main/ESMFold.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3720bcf-7b73-4dd6-b0be-075a0546e596",
   "metadata": {},
   "source": [
    "# ProtGPT2\n",
    "\n",
    "ProtGPT2 ([Ferruz et al 2022](https://www.nature.com/articles/s41467-022-32007-7)) is a language model trained on the protein space that generates de novo protein sequences following the principles of natural ones. The generated proteins display natural amino acid propensities, distantly related to natural ones, as well as unexplored regions of protein space. AlphaFold prediction of ProtGPT2-sequences yields well-folded non-idealized structures with embodiments and large loops and reveals topologies not captured in current structure databases. ProtGPT2 generates sequences in a matter of seconds and is freely available through [Hugging Face](https://huggingface.co/nferruz/ProtGPT2).\n",
    "\n",
    "![image.png](../img/protgpt2.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bbd6fd-9700-41b7-90d4-ff8aba5de9a4",
   "metadata": {
    "id": "QMoeBQnUCK_E"
   },
   "outputs": [],
   "source": [
    "!pip install \"transformers[torch]\" biopython pymsaviz py3Dmol > /dev/null\n",
    "!apt-get install muscle &> /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8358ebea-def6-4f07-88db-7eb3db678b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "#initialise language model\n",
    "protgpt2 = transformers.pipeline('text-generation', model=\"nferruz/ProtGPT2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4fcbb5-f416-4411-baa0-b0271c1df41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "\n",
    "project_name = \"pML_course\"\n",
    "starting_sequence = \"MIQEKDKYVVASVTILESNQ\"\n",
    "sequence_min_length = len(starting_sequence)\n",
    "sequence_max_length = 3 * len(starting_sequence)\n",
    "number_of_generated_sequences = 20\n",
    "\n",
    "\n",
    "#Randomly pick the next amino acid according to its conditional probability distribution? (non-deterministic)\n",
    "do_random_sampling = True\n",
    "\n",
    "#Controls randomness in boltzman distribution. Lower temperature results in less random completions. \n",
    "#As the temperature approaches zero, the model will become deterministic and repetitive. \n",
    "#Higher temperature results in more random completions.\n",
    "sampling_temperature = 1.0\n",
    "\n",
    "#Controlls diversity. 1 means only 1 amino acid with highest probability is considered for each step (token),\n",
    "#resulting in deterministic completions while 950 means 950 amino acids with highest probability are considered at each step. \n",
    "#0 is a special setting meaning no restrictions.\n",
    "top_k_sampling = 950\n",
    "\n",
    "#Controlls diversity. Samples from the smallest possible set of probable amino acids whose cumulative probability exceeds \n",
    "#the probability defined.\n",
    "top_p_filtering = 1.0\n",
    "\n",
    "#Repetition penalty.\n",
    "penalty_for_repetition = 1.2 #@param {type:\"number\"}\n",
    "\n",
    "#Correction factor used for sequence length.\n",
    "#GPT2 measures length in tokens, not amino acids, therefore generated sequences are 3-4 times longer than specified.\n",
    "#You can either use the empirically determined 3.2x correction factor (Default), or none (1), or let the script calculate\n",
    "#the exact factor needed for your specified parameters, however this will result in double the running time.\n",
    "correction_factor = 3.2\n",
    "\n",
    "\n",
    "\n",
    "seed =  423"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c2b4be-8ff7-45fd-996c-b2404d7ef95a",
   "metadata": {},
   "source": [
    "# Sequence Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e153a924-22af-4d10-a2b7-3e50d89012e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set seed for reproducibility\n",
    "transformers.set_seed(seed)\n",
    "\n",
    "#correct sequence lengths\n",
    "corrected_sequence_min_length = int(sequence_min_length/correction_factor, )\n",
    "corrected_sequence_max_length = int(sequence_max_length/correction_factor, )\n",
    "\n",
    "#generate sequences\n",
    "sequences = protgpt2(starting_sequence, \n",
    "                     min_length=corrected_sequence_min_length, \n",
    "                     max_length=corrected_sequence_max_length, \n",
    "                     do_sample=do_random_sampling, \n",
    "                     top_k=top_k_sampling, \n",
    "                     top_p=top_p_filtering, \n",
    "                     temperature=sampling_temperature, \n",
    "                     repetition_penalty=penalty_for_repetition, \n",
    "                     num_return_sequences=number_of_generated_sequences, \n",
    "                     batch_size=1, eos_token_id=0)\n",
    "print(\"Sequences generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25ffff0-cf8b-46a5-9ff9-e29f6af3a913",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cd5627-94a1-4261-be32-b87fb8bcd8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio import SeqIO\n",
    "\n",
    "fastaname = project_name+\"_seed\"+str(seed)+\".fa\"\n",
    "records = []\n",
    "for idx, sequence in enumerate(sequences):\n",
    "    record = SeqRecord(Seq(sequence['generated_text'].replace('\\n', '')),\n",
    "                       id=str(idx),\n",
    "                       name=project_name +\"_\"+ str(idx),\n",
    "                       description=\"ProtGPT2 generated sequence from \" + starting_sequence)\n",
    "    records.append(record)\n",
    "\n",
    "with open(fastaname, \"w\") as output_handle:\n",
    "    SeqIO.write(records, output_handle, \"fasta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260c9bc0-47e9-4631-8d7e-24d04abafa29",
   "metadata": {},
   "source": [
    "# Generating Alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4981f0a7-6c18-4571-bed2-0d04e4dfcba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.Align.Applications import MuscleCommandline\n",
    "from Bio import AlignIO\n",
    "\n",
    "fastaname_aligned = fastaname.replace(\".fa\", \"_aligned.aln\")\n",
    "align_muscle = MuscleCommandline(input=fastaname, out=fastaname_aligned)\n",
    "stdout, stderr = align_muscle()\n",
    "alignment = AlignIO.read(fastaname_aligned, \"fasta\")\n",
    "\n",
    "with open(fastaname_aligned, 'w') as output_handle:\n",
    "  AlignIO.write(alignment, output_handle, \"fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0518d740-b491-4008-8545-b241af92e00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymsaviz import MsaViz, get_msa_testdata\n",
    "\n",
    "mv = MsaViz(alignment)\n",
    "fig = mv.plotfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08757a47-b1a6-41b3-9b5d-b23088cb05a3",
   "metadata": {},
   "source": [
    "# Predicting Structure -- ESMFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b17c24-ba43-47b2-834a-84f41f4903c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.PDB.PDBParser import PDBParser\n",
    "from Bio.PDB.PDBList import PDBList\n",
    "\n",
    "p = PDBParser(PERMISSIVE=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6b39d7-fd60-4444-ab45-94232fe7d637",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import py3Dmol\n",
    "\n",
    "headers = {\n",
    "        'Content-Type': 'application/x-www-form-urlencoded',\n",
    "    }\n",
    "\n",
    "pdb_files = []\n",
    "for record in records:\n",
    "    sequence = str(record.seq)\n",
    "    print(sequence)\n",
    "    response = requests.post('https://api.esmatlas.com/foldSequence/v1/pdb/', headers=headers, data=sequence)\n",
    "    name = record.name\n",
    "    pdb_string = response.content.decode('utf-8')\n",
    "\n",
    "    with open(name+'.pdb', 'w') as f:\n",
    "        f.write(pdb_string)\n",
    "\n",
    "    pdb_files.append(name+'.pdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54811f63-6fa2-4b02-808d-42de04ca5242",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pdb_file in pdb_files:\n",
    "    seq_idx = int(pdb_file.split('.')[0].split(\"_\")[2])\n",
    "    print(\"Showing structure: \"+pdb_file.split('.')[0])\n",
    "    print(\"Sequence: \"+records[seq_idx].seq)\n",
    "    view=py3Dmol.view()\n",
    "    view.addModel(open(pdb_file, 'r').read(),'pdb')\n",
    "    view.zoomTo()\n",
    "    view.setBackgroundColor('white')\n",
    "    #Here we set the visualization style for chain B and C\n",
    "    view.setStyle({'cartoon': {'color':'yellow'}})\n",
    "    view.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
